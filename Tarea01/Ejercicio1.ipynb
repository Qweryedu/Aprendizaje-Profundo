{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 - Redes densas\n",
    "## Eduardo García Alarcón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1. Red de unidades de umbral\n",
    "\n",
    "Programa y evalúa una red de neuronas con funciones de activación escalón unitario que aproxime la operación **XNOR** ($\\odot$) dada por:\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$ \n",
    "|:-----:|:-----:|:---:|\n",
    "|   0   |   0   |  1  |\n",
    "|   0   |   1   |  0  |\n",
    "|   1   |   0   |  0  |\n",
    "|   1   |   1   |  1  |\n",
    "\n",
    "Para ello debes asignarle los pesos y sesgos adecuados a cada neurona manualmente. Explica la elección de la red y los valores de los pesos y sesgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidad de Umbral Lineal\n",
    "La operación que lleva a cabo una neurona articial está dada por la suma pesada evaluada con una función de activación $\\phi$. Una de las primeras funciones de activación utilizadas fue la escalón unitario, definida como\n",
    "\n",
    "$\n",
    "\\phi(x) = \\begin{cases} 1, & \\text{si } x \\geq 0\\\\0, & \\text{en caso contrario}\\end{cases}\n",
    "$\n",
    "\n",
    "Esta se puede llevar a cabo con la siguiente función de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalon(z):\n",
    "  if z >= 0.0:\n",
    "    return 1.0\n",
    "  else:\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona\n",
    "Definimos la neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neurona(x, w, b):\n",
    "  z = w.T @ x + b\n",
    "  return escalon(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestra neurona con $ w = [-10, -10] $ y $b=5$ para obtener la tabla de la compuerta $NOR$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "x_1 \tx_2 \ty_hat\n",
      "-----------------------------\n",
      "0.0 \t0.0\t1.0\n",
      "0.0 \t1.0\t0.0\n",
      "1.0 \t0.0\t0.0\n",
      "1.0 \t1.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "w = np.array([-10, -10])\n",
    "b = 5\n",
    "\n",
    "print('-----------------------------')\n",
    "print('x_1 \\tx_2 \\ty_hat')\n",
    "print('-----------------------------')\n",
    "for i in range(X.shape[0]):\n",
    "  y_hat = neurona(X[i, :].T, w, b)\n",
    "  print('{0} \\t{1}\\t{2}'.format(X[i, 0], X[i, 1], y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sabemos que XNOR está en un espacio no linealmente separable, por lo que necesitamos al menos dos capas para poder realizar el cálculo\n",
    "\n",
    "Desarrollamos la definición de XNOR para entender cómo armar nuetra red con las compuertas más básicas desde la definición de $XOR= ((x_1 \\lor x_2) \\land \\neg(x_1 \\land x_2))$\n",
    "\n",
    "$x_1 \\mathbin{\\odot} x_2 = \\neg((x_1 \\lor x_2) \\land \\neg(x_1 \\land x_2)) = \\neg(x_1 \\lor x_2) \\lor (x_1 \\land x_2) $  \n",
    "Lo cual podemos observar está compuesto con solo 3 compuertas lógicas las cuales ya hemos revisado en clase: NOR, OR y AND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una red multicapa\n",
    "def multicapa(x, w1, b1, w2, b2):\n",
    "  escv = np.vectorize(escalon)\n",
    "  a = escv(np.dot( w1.T, x ) + b1)\n",
    "  return escv( np.dot( w2.T, a ) + b2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora buscamos los valores de pesos y offsets adecuados para aproximar la función\n",
    "\n",
    "Encontrando los valores de pesos y sesgos adecuados, podemos usar esta función para aproximar la computerta XNOR. En clase ya hemos encontrado los pesos y sesgos para las compuertas OR, AND y NOR, por lo que podemos usar estas neuronas con sus correspondientes pesos y sesgos. La red tendría 2 neuronas conectadas a las entradas que realizan las operaciones NOR ($w_{11}^{\\{1\\}} = -10$, $w_{12}^{\\{1\\}} = -10$ y $b_1^{\\{1\\}} = 5$)  y AND ($w_{21}^{\\{1\\}} = 10$, $w_{22}^{\\{1\\}} = 10$ y $b_2^{\\{1\\}} = -15$) respectivamente. La salida de estas 2 neuronas estarían conectadas a una tercera neurona que realiza la operacioón OR ($w_{11}^{\\{2\\}} = 10$, $w_{12}^{\\{2\\}} = 10$ y $b_1^{\\{2\\}} = -5$). En su forma matricial:\n",
    "\n",
    "$$\n",
    "\\mathbf{W}^{\\{1\\}} = \\left[\\begin{matrix}\n",
    "-10 & 10\\\\\n",
    "-10 & 10\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{b}^{\\{1\\}} = \\left[\\begin{matrix}\n",
    "5 \\\\\n",
    "-15\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{W}^{\\{2\\}} = \\left[\\begin{matrix}\n",
    "10\\\\\n",
    "10\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{b}^{\\{2\\}} = \\left[\\begin{matrix}\n",
    "-5\\\\\n",
    "\\end{matrix}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_1 = [[-10  10][-10  10]], b_1 = [  5 -15]\n",
      "W_2 = [[10][10]], b_2 = [-5]\n",
      "-----------------------------\n",
      "x_1 \tx_2 \ty\ty_hat\n",
      "-----------------------------\n",
      "0.0\t0.0\t1.0\t1.0\n",
      "0.0\t1.0\t0.0\t0.0\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "1.0\t1.0\t1.0\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Datos de entrada y salida esperada para XNOR\n",
    "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "y_xnor = np.array([1., 0., 0., 1.])\n",
    "\n",
    "# Pesos y sesgos\n",
    "W1 = np.array([[-10, -10], [10, 10]]).T\n",
    "b1 = np.array([5, -15]).T\n",
    "\n",
    "W2 = np.array([[10], [10]])\n",
    "b2 = np.array([-5])\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'W_1 = [{W1[0, :]}{W1[1, :]}], b_1 = {b1}')\n",
    "print(f'W_2 = [{W2[0]}{W2[1]}], b_2 = {b2}')\n",
    "print(f'-----------------------------')\n",
    "print(f'x_1 \\tx_2 \\ty\\ty_hat')\n",
    "print(f'-----------------------------')\n",
    "for i in range(X.shape[0]):\n",
    "    y_hat = multicapa(X[i].T, W1, b1, W2, b2)\n",
    "    print(f'{X[i, 0]}\\t{X[i, 1]}\\t{y_xnor[i]}\\t{y_hat[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
